{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578acb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore\n",
    "# !pip install tensorflow-macos==2.6.0\n",
    "# !pip3 install keras==2.6.0\n",
    "# !pip3 install imgaug\n",
    "# !pip3 install pillow==8.2.0\n",
    "# !pip install pixellib==0.7.2\n",
    "# !pip install labelme2coco==0.1.2\n",
    "# !pip install mediapipe-silicon # just mediapipe if not m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920e9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from pixellib.torchbackend.instance import instanceSegmentation\n",
    "from IPython.display import Video\n",
    "from witf_embedded import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd76948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test video player\n",
    "resource_dir = '../resources/'\n",
    "video_name = 'in_out_short.mp4'\n",
    "video_path = f'{resource_dir}/input/{video_name}'\n",
    "print(video_path)\n",
    "Video(video_path, width=640, height=360, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a2ac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "# Test if M1 GPU is properly connected\n",
    "if tf.test.gpu_device_name():\n",
    "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "  print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c168f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "/Users/kenjohnson/Documents/Classes/Year 5 Term 2/NVD/WITF/WITF-Embedded/venv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of frames: 1\n",
      "No. of frames: 2\n",
      "No. of frames: 3\n",
      "No. of frames: 4\n",
      "No. of frames: 5\n",
      "No. of frames: 6\n",
      "No. of frames: 7\n",
      "No. of frames: 8\n",
      "No. of frames: 9\n",
      "No. of frames: 10\n",
      "No. of frames: 11\n",
      "No. of frames: 12\n",
      "No. of frames: 13\n",
      "No. of frames: 14\n",
      "No. of frames: 15\n",
      "No. of frames: 16\n",
      "No. of frames: 17\n",
      "No. of frames: 18\n",
      "No. of frames: 19\n",
      "No. of frames: 20\n",
      "No. of frames: 21\n",
      "No. of frames: 22\n",
      "No. of frames: 23\n",
      "No. of frames: 24\n",
      "No. of frames: 25\n",
      "No. of frames: 26\n",
      "No. of frames: 27\n",
      "No. of frames: 28\n",
      "No. of frames: 29\n",
      "No. of frames: 30\n",
      "No. of frames: 31\n",
      "No. of frames: 32\n",
      "No. of frames: 33\n",
      "No. of frames: 34\n",
      "No. of frames: 35\n",
      "No. of frames: 36\n",
      "No. of frames: 37\n",
      "No. of frames: 38\n",
      "No. of frames: 39\n",
      "No. of frames: 40\n",
      "No. of frames: 41\n",
      "No. of frames: 42\n",
      "No. of frames: 43\n",
      "No. of frames: 44\n",
      "No. of frames: 45\n",
      "No. of frames: 46\n",
      "No. of frames: 47\n",
      "No. of frames: 48\n",
      "No. of frames: 49\n",
      "No. of frames: 50\n",
      "No. of frames: 51\n",
      "Processed 52 frames in 324.8 seconds\n",
      "{'boxes': array([[ 370,    6, 2592, 2143]]), 'class_ids': array([0]), 'class_names': ['person'], 'object_counts': Counter({'person': 1}), 'scores': array([99]), 'masks': array([[[[504, 7],\n",
      "         [503, 8],\n",
      "         [497, 8],\n",
      "         ...,\n",
      "         [1894, 8],\n",
      "         [1884, 8],\n",
      "         [1883, 7]]]], dtype=object), 'extracted_objects': []}\n"
     ]
    }
   ],
   "source": [
    "# For videos\n",
    "from pixellib.torchbackend.instance import instanceSegmentation\n",
    "\n",
    "ins = instanceSegmentation()\n",
    "ins.load_model(f'{resource_dir}/models/pointrend_resnet50.pkl')\n",
    "targets = ins.select_target_classes(refrigerator=True, person=True)\n",
    "results, output = ins.process_video(video_path,\n",
    "  frames_per_second=30,\n",
    "  segment_target_classes=targets,\n",
    "  show_bboxes=True,\n",
    "  mask_points_values=True,\n",
    "  output_video_name=f'{resource_dir}/output/in_out_short.avi', \n",
    "  text_size=1, \n",
    "  text_thickness=1)  # type: ignore\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23fc16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedded-env",
   "language": "python",
   "name": "embedded-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "86098936fc1164e28c2cfa7e8635a53e736b1d10987f6f1023cc3163053ec2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
